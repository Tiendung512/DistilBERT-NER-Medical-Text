{"cells":[{"cell_type":"code","execution_count":null,"id":"_cBjX52j_EPb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19142,"status":"ok","timestamp":1712798594212,"user":{"displayName":"Dzung Dinh Tien","userId":"16205593901054329310"},"user_tz":-420},"id":"_cBjX52j_EPb","outputId":"eee56737-c16f-4262-c54c-642ca62437e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/MyDrive/KLTN/NER-medical-text/\")"]},{"cell_type":"code","execution_count":null,"id":"a43dc53f","metadata":{"id":"a43dc53f","pycharm":{"is_executing":true}},"outputs":[],"source":["import os\n","import re\n","import json\n","import shutil"]},{"cell_type":"code","execution_count":null,"id":"e6d9a8ec","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2476,"status":"ok","timestamp":1712798603430,"user":{"displayName":"Dzung Dinh Tien","userId":"16205593901054329310"},"user_tz":-420},"id":"e6d9a8ec","outputId":"97a2c97e-db2a-4b94-f52a-d6a67af7df3b"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import string\n","\n","import nltk\n","from nltk.corpus import stopwords\n","\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"id":"8340a648","metadata":{"id":"8340a648"},"outputs":[],"source":["data_dir = \"data/annotated_json_data\""]},{"cell_type":"code","execution_count":null,"id":"1dc98c47","metadata":{"id":"1dc98c47"},"outputs":[],"source":["entity_to_acronyms = {\n","    'Activity': 'ACT',\n","    'Administration': 'ADM',\n","    'Age': 'AGE',\n","    'Area': 'ARA',\n","    'Biological_attribute': 'BAT',\n","    'Biological_structure': 'BST',\n","    'Clinical_event': 'CLE',\n","    'Color': 'COL',\n","    'Coreference': 'COR',\n","    'Date': 'DAT',\n","    'Detailed_description': 'DET',\n","    'Diagnostic_procedure': 'DIA',\n","    'Disease_disorder': 'DIS',\n","    'Distance': 'DIS',\n","    'Dosage': 'DOS',\n","    'Duration': 'DUR',\n","    'Family_history': 'FAM',\n","    'Frequency': 'FRE',\n","    'Height': 'HEI',\n","    'History': 'HIS',\n","    'Lab_value': 'LAB',\n","    'Mass': 'MAS',\n","    'Medication': 'MED',\n","    'Nonbiological_location': 'NBL',\n","    'Occupation': 'OCC',\n","    'Other_entity': 'OTH',\n","    'Other_event': 'OTE',\n","    'Outcome': 'OUT',\n","    'Personal_background': 'PER',\n","    'Qualitative_concept': 'QUC',\n","    'Quantitative_concept': 'QUC',\n","    'Severity': 'SEV',\n","    'Sex': 'SEX',\n","    'Shape': 'SHA',\n","    'Sign_symptom': 'SIG',\n","    'Subject': 'SUB',\n","    'Texture': 'TEX',\n","    'Therapeutic_procedure': 'THP',\n","    'Time': 'TIM',\n","    'Volume': 'VOL',\n","    'Weight': 'WEI'\n","}\n","\n","\n","acronyms_to_entities = {v: k for k, v in entity_to_acronyms.items()}"]},{"cell_type":"markdown","id":"4f5ecee9","metadata":{"id":"4f5ecee9"},"source":["## Load Data"]},{"cell_type":"code","execution_count":null,"id":"62d56618","metadata":{"id":"62d56618"},"outputs":[],"source":["# Open the JSON file for reading\n","with open(os.path.join(data_dir, \"annotated_data.json\"), 'r') as f:\n","\n","    # Load the JSON data into a dictionary\n","    data = json.load(f)"]},{"cell_type":"markdown","id":"f37405cd","metadata":{"id":"f37405cd"},"source":["## Data Cleaning"]},{"cell_type":"code","execution_count":null,"id":"36a4b056","metadata":{"id":"36a4b056"},"outputs":[],"source":["def remove_trailing_punctuation(token):\n","    \"\"\"\n","    Removes trailing punctuation from a token.\n","\n","    Args:\n","        token (str): A string representing the token to be cleaned.\n","\n","    Returns:\n","        str: The cleaned token with trailing punctuation removed.\n","    \"\"\"\n","    while token and re.search(r'[^\\w\\s\\']', token[-1]):\n","        token = token[:-1]\n","\n","    return token"]},{"cell_type":"code","execution_count":null,"id":"6febeb15","metadata":{"id":"6febeb15"},"outputs":[],"source":["def split_text(text):\n","\n","    regex_match = r'[^\\s\\u200a\\-\\u2010-\\u2015\\u2212\\uff0d]+'  # r'[^\\s\\u200a\\-\\—\\–]+'\n","\n","    tokens = []\n","    start_end_ranges = []\n","\n","    sentence_breaks = []\n","\n","    start_idx = 0\n","\n","    for sentence in text.split('\\n'):\n","        words = [match.group(0) for match in re.finditer(regex_match, sentence)]\n","        processed_words = list(map(remove_trailing_punctuation, words))\n","        sentence_indices = [(match.start(), match.start() + len(token)) for match, token in\n","                            zip(re.finditer(regex_match, sentence), processed_words)]\n","\n","        # Update the indices to account for the current sentence's position in the entire text\n","        sentence_indices = [(start_idx + start, start_idx + end) for start, end in sentence_indices]\n","\n","        start_end_ranges.extend(sentence_indices)\n","        tokens.extend(processed_words)\n","\n","        sentence_breaks.append(len(tokens))\n","\n","        start_idx += len(sentence) + 1\n","    return tokens, start_end_ranges, sentence_breaks"]},{"cell_type":"code","execution_count":null,"id":"8f24ce89","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1712798638794,"user":{"displayName":"Dzung Dinh Tien","userId":"16205593901054329310"},"user_tz":-420},"id":"8f24ce89","outputId":"e3f07108-95c5-404a-a2db-0504184dd173"},"outputs":[{"name":"stdout","output_type":"stream","text":["(['CASE', 'A', '28', 'year', 'old', 'previously', 'healthy', 'man', 'presented', 'with', 'a', '6', 'week', 'history', 'of', 'palpitations', 'The', 'symp'], [(0, 4), (6, 7), (8, 10), (11, 15), (16, 19), (20, 30), (31, 38), (39, 42), (43, 52), (53, 57), (58, 59), (60, 61), (62, 66), (67, 74), (75, 77), (78, 90), (92, 95), (96, 100)], [16, 18])\n"]}],"source":["for doc_id, doc in data.items():\n","    print(split_text(doc['text'][:100]))\n","    break"]},{"cell_type":"markdown","id":"decc4513","metadata":{"id":"decc4513"},"source":["## Convert to BIO format"]},{"cell_type":"code","execution_count":null,"id":"bde515db","metadata":{"id":"bde515db"},"outputs":[],"source":["def tag_token(tokens, tags, token_pos, entity):\n","\n","    stop_words = stopwords.words('english')\n","\n","    tag = entity_to_acronyms[entity]\n","\n","    if token_pos > 0 and f'{tag}' in tags[token_pos - 1]:\n","            tags[token_pos] = f'I-{tag}'\n","    elif tokens[token_pos] not in stop_words:\n","            tags[token_pos] = f'B-{tag}'\n","\n","    return tags\n"]},{"cell_type":"code","execution_count":null,"id":"d4a93f10","metadata":{"id":"d4a93f10"},"outputs":[],"source":["def write_bio_files(output_file_path, tokens, tags, sentence_breaks):\n","\n","    # Write the tags to a .bio file\n","    with open(output_file_path, 'w') as f:\n","        for i in range(len(tokens)):\n","            token = tokens[i].strip()\n","            if token:\n","                if i in sentence_breaks:\n","                    f.write(\"\\n\")\n","                f.write(f\"{tokens[i]}\\t{tags[i]}\\n\")\n"]},{"cell_type":"code","execution_count":null,"id":"91c0fcd1","metadata":{"id":"91c0fcd1"},"outputs":[],"source":["def convert_ann_to_bio(data, output_dir, filtered_entities=[]):\n","\n","    if os.path.exists(output_dir):\n","        # Delete the contents of the directory\n","        shutil.rmtree(output_dir)\n","    # Recreate the directory\n","    os.makedirs(output_dir)\n","\n","\n","    for file_id in data:\n","        text = data[file_id]['text']\n","        annotations = data[file_id]['annotations']\n","\n","        # Tokenizing\n","        tokens, token2text, sentence_breaks = split_text(text)\n","\n","        # Initialize the tags\n","        tags = ['O'] * len(tokens)\n","\n","        ann_pos = 0\n","        token_pos = 0\n","\n","        while ann_pos < len(annotations) and token_pos < len(tokens):\n","\n","            label = annotations[ann_pos]['label']\n","            start = annotations[ann_pos]['start']\n","            end = annotations[ann_pos]['end']\n","\n","            if filtered_entities:\n","                if label not in filtered_entities:\n","                    # increment to access next annotation\n","                    ann_pos += 1\n","                    continue\n","\n","            ann_word = text[start:end]\n","\n","            # find the next word that fall between the annotation start and end\n","            while token_pos < len(tokens) and token2text[token_pos][0] < start:\n","\n","                token_pos += 1\n","\n","            if tokens[token_pos] == ann_word or \\\n","                ann_word in tokens[token_pos] or \\\n","                re.sub(r'\\W+', '', ann_word) in re.sub(r'\\W+', '', tokens[token_pos]):\n","                tag_token(tokens, tags, token_pos, label)\n","            elif ann_word in tokens[token_pos - 1] or \\\n","                ann_word in tokens[token_pos - 1] or \\\n","                re.sub(r'\\W+', '', ann_word) in re.sub(r'\\W+', '', tokens[token_pos - 1]):\n","                tag_token(tokens, tags, token_pos - 1, label)\n","            else:\n","                print(tokens[token_pos], tokens[token_pos - 1], ann_word, label)\n","\n","            # increment to access next annotation\n","            ann_pos += 1\n","\n","        # write to bio file\n","        write_bio_files(os.path.join(output_dir, f\"{file_id}.bio\"), tokens, tags, sentence_breaks)\n","    print(\"Conversion complete\")"]},{"cell_type":"code","execution_count":null,"id":"559018a5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9180,"status":"ok","timestamp":1712798647971,"user":{"displayName":"Dzung Dinh Tien","userId":"16205593901054329310"},"user_tz":-420},"id":"559018a5","outputId":"7f7061f8-b7a6-4fd4-c16a-e426066512c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Conversion complete\n"]}],"source":["convert_ann_to_bio(data, data_dir)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
